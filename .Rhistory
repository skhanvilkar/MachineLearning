session_password = password)
submit_form(pgsession, filled_form)
user_url <- "https://www.linkedin.com/public-profile/settings?trk=d_flagship3_profile_self_view_public_profile&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base%3BjL0VjwJaS6%2BqgfgTyHThtA%3D%3D/"
username <- 'skhanvilkar@outlook.com'
password <- 'BlessMeJesus#1417'
library(rvest)
linkedin_url <- "https://linkedin.com/"
pgsession <- html_session(linkedin_url)
pgform <- html_form(pgsession)[[1]]
filled_form <- set_values(pgform,
session_key = username,
session_password = password)
submit_form(pgsession, filled_form)
pgsession <- jump_to(pgsession, user_url)
page_html <- read_html(pgsession)
name <-
page_html %>% html_nodes("#name") %>% html_text()
location <-
page_html %>% html_nodes("#location .locality") %>% html_text()
num_connections <-
page_html %>% html_nodes(".member-connections strong") %>% html_text()
summary <-
page_html %>% html_nodes("#summary-item-view") %>% html_text()
skills_nodes <-
page_html %>% html_nodes("#profile-skills .skill-pill")
skills <-
lapply(skills_nodes, function(node) {
num <- node %>% html_nodes(".num-endorsements") %>% html_text()
name <- node %>% html_nodes(".endorse-item-name-text") %>% html_text()
data.frame(name = name, num = num)
})
skills <- do.call(rbind, skills)
list(
name = name,
location = location,
num_connections = num_connections,
summary = summary,
skills = skills
)
}
skills
scrape_linkedin()
user_url <- "https://www.linkedin.com/in/daattali"
user_url <- "https://www.linkedin.com/public-profile/settings?trk=d_flagship3_profile_self_view_public_profile&lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base%3BjL0VjwJaS6%2BqgfgTyHThtA%3D%3D/"
username <- 'skhanvilkar@outlook.com'
password <- 'BlessMeJesus#1417'
library(rvest)
linkedin_url <- "https://linkedin.com/"
pgsession <- html_session(linkedin_url)
pgform <- html_form(pgsession)[[1]]
filled_form <- set_values(pgform,
session_key = username,
session_password = password)
submit_form(pgsession, filled_form)
pgsession <- jump_to(pgsession, user_url)
page_html <- read_html(pgsession)
name <-
page_html %>% html_nodes("#name") %>% html_text()
location <-
page_html %>% html_nodes("#location .locality") %>% html_text()
num_connections <-
page_html %>% html_nodes(".member-connections strong") %>% html_text()
summary <-
page_html %>% html_nodes("#summary-item-view") %>% html_text()
skills_nodes <-
page_html %>% html_nodes("#profile-skills .skill-pill")
skills <-
lapply(skills_nodes, function(node) {
num <- node %>% html_nodes(".num-endorsements") %>% html_text()
name <- node %>% html_nodes(".endorse-item-name-text") %>% html_text()
data.frame(name = name, num = num)
})
skills <- do.call(rbind, skills)
list(
name = name,
location = location,
num_connections = num_connections,
summary = summary,
skills = skills
)
}
installr::installr()
installr::installr("MikTeX")
install.packages("MikTeX")
Sys.getenv("PATH")
Sys.setenv(PATH=paste(Sys.getenv("PATH"),"C:/Program Files/MiKTeX 2.9/miktex/bin/x64/",sep=";"))
View(sgatable)
user_url <- "https://www.best-in-class.com/bestp/domrep.nsf/products/db-benchmarking-pharmaceutical-chemistry-manufacturing-control-operations-resources-investments-and-activities!OpenDocument#"
user_url[1:50]
user_url <- "https://www.best-in-class.com/bestp/domrep.nsf/products/"
user_url[1:50]
user_url <- "https://www.best-in-class.com/"
user_url[1:50]
user_url <- "http://www.best-in-class.com/"
user_url[1:50]
head(user_url)
inst <- "http://www.sec.gov/Archives/edgar/data/1223389/000122338914000023/conn-20141031.xml"
options(stringsAsFactors = FALSE)
xbrl.vars <- xbrlDoAll(inst)
xbrl.sec <- xbrlSECdev01(xbrl.vars)
xbrl.sec$showStatements()
install.packages("XBRL")
inst <- "http://www.sec.gov/Archives/edgar/data/1223389/000122338914000023/conn-20141031.xml"
options(stringsAsFactors = FALSE)
xbrl.vars <- xbrlDoAll(inst)
xbrl.sec <- xbrlSECdev01(xbrl.vars)
xbrl.sec$showStatements()
conn.data <- xbrl.sec$showStatements()
cfia  <- readLines("https://www.sec.gov/divisions/corpfin/organization/cfia-c.htm")
head(cfia)
head(cfia,10)
library(htmltab)
url <- "https://www.sec.gov/divisions/corpfin/organization/cfia-c.htm"
cfia <- htmltab(doc = url, which = "//th[text() = 'Ability']/ancestor::table")
head(cfia)
install.packages("htmltab")
library(htmltab)
url <- "https://www.sec.gov/divisions/corpfin/organization/cfia-c.htm"
cfia <- htmltab(doc = url, which = "//th[text() = 'Ability']/ancestor::table")
head(cfia)
head(cfia,10)
head(cfia,30)
cfia <- htmltab(doc = url, which = "<td>C &amp; F FINANCIAL CORP</td>")
head(cfia,30)
cfia <- htmltab(doc = url, which = "<th>Company Name</th>")
head(cfia,30)
install.packages("XML")
library(XML)
library(RCurl)
library(dplyr)
fileXML <- "https://www.sec.gov/divisions/corpfin/organization/cfia-c.htm" ## remove s from https
doc <- xmlTreeParse(fileXML,useInternal = TRUE) ## loads the document in R Use Internal allows to include all the nodes
# using RCurl, can leave https.  Use getURL first, then parse with xmlParse
doc
library(rvest)
APQCFN <- read_html("https://www.apqc.org/knowledge-base/download/")
head(APQCFN,20)
APQCFN %>%
html_nodes("body class")
library(rvest)
APQCFN <- read_html("https://www.apqc.org/knowledge-base/download/")
head(APQCFN,20)
APQCFN %>%
html_nodes("p")
APQCFN[1:10]
APQCFN <- read_html("https://www.apqc.org/knowledge-base/download/")
head(APQCFN,20)
APQCFN %>%
html_nodes("div")
APQCFN[1:10]
APQCFN %>%
html_nodes("table")
APQCFN[1:10]
APQCFN %>%
html_nodes("embed")
APQCFN[1:10]
install.packages("maggrittr")
APQCFN %>%
html_nodes("ul")
APQCFN[1:10]
APQCFN[1:4]
APQCFN %>%
html_nodes("li")
APQCFN[1:4]
li_text <- scraping_wiki %>%
html_nodes("li") %>%
html_text()
length(li_text)
li_text <- APQCFN %>%
html_nodes("li") %>%
html_text()
length(li_text)
li_text[1:117]
li_text <- APQCFN %>%
html_nodes("div") %>%
html_text()
li_text[1:117]
"https://www.apqc.org/knowledge-base/download/"
read_html() %>%
html_nodes("[class='sidebar_button']") %>%
html_attr("href")
library(xml2)
xml <- read_html(webpage)
l <- as_list(xml)[[1]][[1]][[1]][[1]]  #not sure why you need to go this deep.
l2 <- l[sapply(l, attr, ".class") == "sidebar_button"]
sapply(l2, attr, "href")
library(rvest)
install.packages("maggrittr")
APQCFN <- read_html("https://www.apqc.org/knowledge-base/download/")
head(APQCFN,20)
APQCFN %>%
html_nodes("li")
APQCFN[1:4]
library(tidyverse)
download.file("https://www.apqc.org/knowledge-base/download/355907/K06255_Finance%20Org%20Benchmarks_Cross%20Industry.pdf", "K06255_Finance%20Org%20Benchmarks_Cross%20Industry.pdf", mode = "wb")
APQCXFN <- pdf_text("K06255_Finance%20Org%20Benchmarks_Cross%20Industry.pdf")
df <- APQCXFN[56] %>%
read_lines() %>%    # separate lines
grep('^\\s{2}\\w', ., value = TRUE) %>%    # select lines with states, which start with space, space, letter
paste(collapse = '\n') %>%    # recombine
read_fwf(fwf_empty(.)) %>%    # read as fixed-width file
mutate_at(-1, parse_number) %>%    # make numbers numbers
mutate(X1 = sub('*', '', X1, fixed = TRUE))    # get rid of asterisks in state names
install.packages("XML")
library(XML)
library(RCurl)
library(dplyr)
fileXML <- "http://api.walmartlabs.com/v1/stores?format=json&apiKey=store+locator" ## remove s from https
doc <- xmlTreeParse(fileXML,useInternal = TRUE) ## loads the document in R Use Internal allows to include all the nodes
# using RCurl, can leave https.  Use getURL first, then parse with xmlParse
xData <- getURL(fileXML) # This allows you to use https
doc <- xmlParse(xData)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
fileXML <- "http://api.walmartlabs.com/v1/stores?format=json&apiKey=store+locator" ## remove s from https
doc <- xmlTreeParse(fileXML,useInternal = TRUE) ## loads the document in R Use Internal allows to include all the nodes
# using RCurl, can leave https.  Use getURL first, then parse with xmlParse
xData <- getURL(fileXML) # This allows you to use https
doc <- xmlParse(xData)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
library(XML)
library(RCurl)
library(dplyr)
fileXML <- "http://api.walmartlabs.com/v1/stores?format=json&apiKey=store+locator" ## remove s from https
doc <- xmlTreeParse(fileXML,useInternal = TRUE) ## loads the document in R Use Internal allows to include all the nodes
# using RCurl, can leave https.  Use getURL first, then parse with xmlParse
xData <- getURL(fileXML) # This allows you to use https
doc <- xmlParse(xData)
rootNode <- xmlRoot(doc)
fileXML <- "http://api.walmartlabs.com/v1/stores?format=json&apiKey=store+locator" ## remove s from https
doc <- xmlTreeParse(fileXML,useInternal = TRUE) ## loads the document in R Use Internal allows to include all the nodes
fileXML <- "https://api.walmartlabs.com/v1/stores?format=json&apiKey=store+locator" ## remove s from https
doc <- xmlTreeParse(fileXML,useInternal = TRUE) ## loads the document in R Use Internal allows to include all the nodes
fileXML
library(caret)
install.packages("caret")
library(caret)
library(kernlab)
data(spam)
head(spam,10)
InTrain <- createDataPartition(y=spam$make, p=0.75, list=F)
InTrain <- CreateDataPartition(y=spam$make, p=0.75, list=F)
library(caret)
library(kernlab)
library(caret)
Install.packages("kernlab")
Install.packages("Kernlab")
library(kernlab)
Train <- createDataPartition(y=spam$make, p=0.75, list=FALSE)
Train <- CreateDataPartition(y=spam$make, p=0.75, list=FALSE)
Train <- createDataPartition(y=spam$make, p=0.75, list=FALSE)
set.seed(135)
set.seed(1235)
modelFit2 <- train(type ~.,data=training,method="glm")
modelFit2
modelFit2 <- train(type ~.,data=training,method="glm")
library(caret)
library(rpart)
library(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
library(RColorBrewer)
library(RGtk2)
library(rattle)
install.packages("RGtk2")
install.packages("RGtk2")
library(RGtk2)
library(RColorBrewer)
library(rattle)
install.packages("rattle")
library(rattle)
library(randomForest)
install.packages("randomForest")
library(randomForest)
getwd()
setwd("C:/Users/skhanvilkar/Documents/MachineLearningWk4")
Train <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
Test  <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
# download the datasets
dt_training <- read.csv(url(Train))
dt_testing  <- read.csv(url(Test))
features <- names(dt_testing[,colSums(is.na(dt_testing)) == 0])[8:59]
# Only use features used in testing cases.
dt_training <- dt_training[,c(features,"classe")]
dt_testing <- dt_testing[,c(features,"problem_id")]
dim(dt_training); dim(dt_testing);
inTrain <- createDataPartition(dt_training$classe, p=0.6, list=FALSE)
training <- dt_training[inTrain,]
testing <- dt_training[-inTrain,]
dim(training)
dim(dt_training); dim(dt_testing);
install.packages("munsell")
install.packages("munsell")
set.seed(12345)
inTrain <- createDataPartition(dt_training$classe, p=0.6, list=FALSE)
training <- dt_training[inTrain,]
testing <- dt_training[-inTrain,]
dim(training)
set.seed(12345)
inTrain <- createDataPartition(dt_training$classe, p=0.6, list=FALSE)
training <- dt_training[Train,]
testing <- dt_training[-Train,]
dim(training)
dim(testing)
testing <- dt_training[-Train,]
set.seed(12345)
inTrain <- createDataPartition(dt_training$classe, p=0.6, list=FALSE)
training <- dt_training[inTrain,]
testing <- dt_training[-inTrain,]
dim(training)
dim(testing)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
UrlTrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
UrlTest  <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
# download the datasets
dt_training <- read.csv(url(UrlTrain))
dt_testing  <- read.csv(url(UrlTest))
features <- names(dt_testing[,colSums(is.na(dt_testing)) == 0])[8:59]
# Only use features used in testing cases.
dt_training <- dt_training[,c(features,"classe")]
dt_testing <- dt_testing[,c(features,"problem_id")]
dim(dt_training); dim(dt_testing);
set.seed(12345)
inTrain <- createDataPartition(dt_training$classe, p=0.6, list=FALSE)
training <- dt_training[inTrain,]
testing <- dt_training[-inTrain,]
dim(training)
dim(testing)
testing <- dt_training[-inTrain,]
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
myTesting <- training[-inTrain, ]
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ];
myTesting <- training[-inTrain, ];
dim(myTraining)
dim(myTesting)
head(training,10)
head(testing,10)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
install.packages("munsell")
install.packages("munsell")
library(munsell)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
SessionInfo()
library(caret)
install.packages("caret")
library(caret)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
SessionInfo()
install.packages("munsell")
SessionInfo()
library(munsell)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
install.packages("caret")
install.packages("numDeriv")
library(caret)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
UrlTrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
UrlTest  <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
# download the datasets
dt_training <- read.csv(url(UrlTrain))
dt_testing  <- read.csv(url(UrlTest))
features <- names(dt_testing[,colSums(is.na(dt_testing)) == 0])[8:59]
# Only use features used in testing cases.
dt_training <- dt_training[,c(features,"classe")]
dt_testing <- dt_testing[,c(features,"problem_id")]
dim(dt_training); dim(dt_testing);
set.seed(12345)
inTrain <- createDataPartition(dt_training$classe, p=0.6, list=FALSE)
training <- dt_training[inTrain,]
testing <- dt_training[-inTrain,]
dim(training)
dim(testing)
set.seed(12345)
inTrain <- createDataPartition(dt_training$classe, p=0.6, list=FALSE)
training <- dt_training[inTrain,]
testing <- dt_training[-inTrain,]
dim(training)
dim(testing)
modFitDT <- rpart(classe ~ ., data = training, method="class")
fancyRpartPlot(modFitDT)
set.seed(12345)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
SessionInfo()
install.packages("caret")
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
install.packages("numDeriv")
library(caret)
library(rpart)
##install.packages("rpart.plot")
library(rpart.plot)
#install.packages("RGtk2")
library(RColorBrewer)
library(RGtk2)
#install.packages("rattle")
library(rattle)
install.packages("randomForest")
library(randomForest)
install.packages("munsell")
install.packages("munsell")
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ];
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
library(caret)
SessionInfo()
install.packages("SessionInfo")
y
install.packages("Sessioninfo")
install.packages("sessioninfo")
sessioninfo()
sessioninfo::
sessionInfo()
install.packages("caret",
repos = "http://cran.r-project.org",
dependencies = c("Depends", "Imports", "Suggests"))
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ];
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
sessionInfo()
sessioninfo()
sessionInfo()
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ];
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
install.packages("caret")
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ];
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
sessionInfo()
library(caret)
sessionInfo()
sessionInfo()
sessionInfo()
install.packages("munsell")
install.packages("munsell")
install.packages("sessioninfo")
sessionInfo()
sessionInfo()
install.packages(c('caret', 'skimr', 'RANN', 'randomForest', 'fastAdaboost', 'gbm', 'xgboost', 'caretEnsemble', 'C50', 'earth'))
# Load the caret package
library(caret)
install.packages(c("caret", "skimr", "RANN", "randomForest", "fastAdaboost", "gbm", "xgboost", "caretEnsemble", "C50", "earth"))
sessionInfo()
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ];
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
set.seed(12345)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ];
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
library(tidyselect)
sessionInfo()
install.packages("tidyselect")
install.packages("tidyselect")
install.packages("caret")
sessionInfo()
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ];
myTesting <- training[-inTrain, ]
dim(myTraining)
dim(myTesting)
library(tidyselect)
library(caret)
